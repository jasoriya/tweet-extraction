{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tokenizers\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tf-roberta/vocab-roberta-base.json\n",
      "/kaggle/input/tf-roberta/pretrained-roberta-base.h5\n",
      "/kaggle/input/tf-roberta/merges-roberta-base.txt\n",
      "/kaggle/input/tf-roberta/config-roberta-base.json\n",
      "/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n",
      "/kaggle/input/tweet-sentiment-extraction/test.csv\n",
      "/kaggle/input/tweet-sentiment-extraction/train.csv\n",
      "/kaggle/input/tweetextraction-trainedroberta-v0/v0-roberta-4.h5\n",
      "/kaggle/input/tweetextraction-trainedroberta-v0/v0-roberta-1.h5\n",
      "/kaggle/input/tweetextraction-trainedroberta-v0/v0-roberta-3.h5\n",
      "/kaggle/input/tweetextraction-trainedroberta-v0/v0-roberta-0.h5\n",
      "/kaggle/input/tweetextraction-trainedroberta-v0/v0-roberta-2.h5\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data Pre-processing and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 27481 data points\n",
      "Testing set has 3534 data points\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set has {} data points\".format(len(train)))\n",
    "print(\"Testing set has {} data points\".format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The pretrained RoBERTa model and tokenizer are from huggingface [transformers](https://huggingface.co/transformers/main_classes/model.html?highlight=save_pretrained) library. They can be downloaded by using the `from_pretrained()` method or attached to a kaggle kerned from [here](https://www.kaggle.com/cdeotte/tf-roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset:\n",
    "    def __init__(self, data_df, tokenizer, train=True, max_len=96):\n",
    "        self.data = data_df.dropna(axis=0).reset_index(drop=True)\n",
    "        self.is_train = True if train else False\n",
    "        self.sentiment_tokens = {\n",
    "            'positive': tokenizer.encode('positive').ids[0], \n",
    "            'negative': tokenizer.encode('negative').ids[0],\n",
    "            'neutral': tokenizer.encode('neutral').ids[0]\n",
    "        }\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def ByteLevelBPEPreprocessor(self, text, selected_text, sentiment):\n",
    "        \n",
    "        text = \" \" + \" \".join(text.split())\n",
    "        enc = self.tokenizer.encode(text)\n",
    "        s_tok = self.sentiment_tokens[sentiment]\n",
    "        \n",
    "        # Get InputIDs\n",
    "        input_ids = np.ones((self.max_len),\n",
    "                            dtype = 'int32')\n",
    "        input_ids[:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "\n",
    "        # Get Attention mask\n",
    "        attention_mask = np.zeros((self.max_len),\n",
    "                                  dtype='int32')\n",
    "        attention_mask[:len(enc.ids)+5] = 1\n",
    "        \n",
    "        if self.is_train:\n",
    "            selected_text = \" \".join(selected_text.split())\n",
    "            idx = text.find(selected_text)\n",
    "            char_tokens = np.zeros((len(text)))\n",
    "            char_tokens[idx:idx+len(selected_text)] = 1\n",
    "            # if text has ' ' prefix\n",
    "            if text[idx-1] == ' ': \n",
    "                char_tokens[idx-1] = 1\n",
    "                \n",
    "            # Get start and end token for selected_text in input IDs\n",
    "            start_tokens = np.zeros((self.max_len),\n",
    "                                    dtype='int32')\n",
    "            end_tokens = np.zeros((self.max_len),\n",
    "                                  dtype='int32')\n",
    "            ptr_idx = 0\n",
    "            label_idx = list()\n",
    "            for i, enc_id in enumerate(enc.ids):\n",
    "                sub_word = self.tokenizer.decode([enc_id])\n",
    "                if sum(char_tokens[ptr_idx:ptr_idx+len(sub_word)]) > 0:\n",
    "                    label_idx.append(i)\n",
    "                ptr_idx += len(sub_word)\n",
    "            if label_idx:\n",
    "                # + 1 as we added prefix before\n",
    "                start_tokens[label_idx[0] + 1] = 1\n",
    "                end_tokens[label_idx[-1] + 1] = 1\n",
    "            return input_ids, attention_mask, start_tokens, end_tokens\n",
    "        \n",
    "        return input_ids, attention_mask\n",
    "            \n",
    "    def __call__(self):\n",
    "        data_len = len(self.data)\n",
    "        input_ids = np.ones((data_len, self.max_len), \n",
    "                            dtype='int32')\n",
    "        attention_mask = np.zeros((data_len, self.max_len), \n",
    "                                  dtype='int32')\n",
    "        token_type_ids = np.zeros((data_len, self.max_len),\n",
    "                                  dtype='int32')\n",
    "        if self.is_train:\n",
    "            start_tokens = np.zeros((data_len, self.max_len),\n",
    "                                    dtype='int32')\n",
    "            end_tokens = np.zeros((data_len, self.max_len),\n",
    "                                  dtype='int32')\n",
    "        for i, row in tqdm(self.data.iterrows(), total=len(self.data)):\n",
    "            out = self.ByteLevelBPEPreprocessor(\n",
    "                row['text'], \n",
    "                row['selected_text'] if self.is_train else None, \n",
    "                row['sentiment']\n",
    "            )\n",
    "            if self.is_train:\n",
    "                input_ids[i], attention_mask[i], start_tokens[i], end_tokens[i] = out\n",
    "            else:\n",
    "                input_ids[i], attention_mask[i] = out\n",
    "        if self.is_train:\n",
    "            return input_ids, attention_mask, token_type_ids, start_tokens, end_tokens\n",
    "        return input_ids, attention_mask, token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerQA:\n",
    "    def __init__(self, max_len, model_path, model_save_path, \n",
    "                 tokenizer, fit=True):\n",
    "        self.max_len = max_len\n",
    "        self.model_path = model_path\n",
    "        self.model_save_path = model_save_path\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def roberta_model(self):\n",
    "        input_ids = tf.keras.layers.Input((self.max_len,),\n",
    "                                          dtype=tf.int32)\n",
    "        attention_mask = tf.keras.layers.Input((self.max_len,),\n",
    "                                               dtype=tf.int32)\n",
    "        token_type_ids = tf.keras.layers.Input((self.max_len,),\n",
    "                                               dtype=tf.int32)\n",
    "\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            os.path.join(self.model_path, 'config-roberta-base.json')\n",
    "        )\n",
    "        roberta_model = TFRobertaModel.from_pretrained(\n",
    "            os.path.join(self.model_path, 'pretrained-roberta-base.h5'),\n",
    "            config=config\n",
    "        )\n",
    "        x = roberta_model(inputs=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids)\n",
    "\n",
    "        x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "        x1 = tf.keras.layers.Conv1D(1,1)(x1)\n",
    "        x1 = tf.keras.layers.Flatten()(x1)\n",
    "        x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "\n",
    "        x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
    "        x2 = tf.keras.layers.Conv1D(1,1)(x2)\n",
    "        x2 = tf.keras.layers.Flatten()(x2)\n",
    "        x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "\n",
    "        model = tf.keras.models.Model(\n",
    "            inputs=[input_ids, attention_mask, token_type_ids], \n",
    "            outputs=[x1,x2]\n",
    "        )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def jaccard(self, str1, str2):\n",
    "        a = set(str1.lower().split()) \n",
    "        b = set(str2.lower().split())\n",
    "        if (len(a)==0) & (len(b)==0): return 0.5\n",
    "        c = a.intersection(b)\n",
    "        return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "    \n",
    "    def get_model_selected_text(self, data_df, preds_start, preds_end):\n",
    "        st_list = []\n",
    "        for k in range(len(data_df)):\n",
    "            idx_start = np.argmax(preds_start[k,])\n",
    "            idx_end = np.argmax(preds_end[k,])\n",
    "            if idx_start > idx_end:\n",
    "                st = data_df.loc[k,'text']\n",
    "#                 if data_df.loc[k, 'sentiment'] != 'neutral':\n",
    "#                     st = st.split()[idx_start]\n",
    "            else:\n",
    "                text = \" \" + \" \".join(data_df.loc[k,'text'].split())\n",
    "                enc = self.tokenizer.encode(text)\n",
    "                st = self.tokenizer.decode(enc.ids[idx_start-1:idx_end])\n",
    "            st_list.append(st)\n",
    "        return st_list\n",
    "    \n",
    "    def fit(self, train_df, input_ids, attention_mask, \n",
    "            token_type_ids, start_tokens, end_tokens, \n",
    "            stratify_y, VER='v0', verbose=1):\n",
    "        avg_score = []\n",
    "        oof_start = np.zeros((input_ids.shape[0],\n",
    "                              self.max_len))\n",
    "        oof_end = np.zeros((input_ids.shape[0],\n",
    "                            self.max_len))\n",
    "        skf = StratifiedKFold(n_splits=5,\n",
    "                              shuffle=True,\n",
    "                              random_state=42)\n",
    "\n",
    "        for fold, (idxT,idxV) in enumerate(skf.split(input_ids,\n",
    "                                                     stratify_y)):\n",
    "            print('Training FOLD {}:'.format(fold+1))\n",
    "            K.clear_session()\n",
    "            model = self.roberta_model()\n",
    "            model_filename = os.path.join(\n",
    "                self.model_save_path, \n",
    "                '{}-roberta-{}.h5'.format(VER, fold)\n",
    "            )\n",
    "            sv = tf.keras.callbacks.ModelCheckpoint(\n",
    "                model_filename, \n",
    "                monitor='val_loss', \n",
    "                verbose=verbose, \n",
    "                save_best_only=True,\n",
    "                save_weights_only=True, \n",
    "                mode='auto', \n",
    "                save_freq='epoch'\n",
    "            )\n",
    "            model.fit([input_ids[idxT,], \n",
    "                       attention_mask[idxT,], \n",
    "                       token_type_ids[idxT,]], \n",
    "                      [start_tokens[idxT,], end_tokens[idxT,]],\n",
    "                      epochs=3, \n",
    "                      batch_size=32, \n",
    "                      verbose=verbose, \n",
    "                      callbacks=[sv],\n",
    "                      validation_data=(\n",
    "                          [\n",
    "                              input_ids[idxV,],\n",
    "                              attention_mask[idxV,],\n",
    "                              token_type_ids[idxV,]\n",
    "                          ], \n",
    "                          [start_tokens[idxV,], end_tokens[idxV,]]\n",
    "                      )\n",
    "                     )\n",
    "            # Load best saved model from disk\n",
    "            print('Loading model...')\n",
    "            model.load_weights(model_filename)\n",
    "            \n",
    "            # Predicting OOF samples\n",
    "            print('Predicting OOF...')\n",
    "            oof_start[idxV,],oof_end[idxV,] = model.predict(\n",
    "                [\n",
    "                    input_ids[idxV,],\n",
    "                    attention_mask[idxV,],\n",
    "                    token_type_ids[idxV,]\n",
    "                ],\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            pred_df = train_df.loc[idxV].reset_index(drop=True)\n",
    "            pred_df['oof_st'] = self.get_model_selected_text(\n",
    "                data_df=pred_df,\n",
    "                preds_start=oof_start[idxV,],\n",
    "                preds_end=oof_end[idxV,]\n",
    "            )\n",
    "            fold_val_score = pred_df.apply(\n",
    "                lambda x: self.jaccard(x['selected_text'], \n",
    "                                       x['oof_st']\n",
    "                                      ),\n",
    "                axis=1\n",
    "            ).mean()\n",
    "            avg_score.append(fold_val_score)\n",
    "            print('>>>> FOLD {} Jaccard score = {}'.format(fold+1, \n",
    "                                                           fold_val_score))\n",
    "    def predict(self, pred_df, input_ids, attention_mask, \n",
    "                token_type_ids, n_models, VER='v0', verbose=1):\n",
    "        preds_start = np.zeros((input_ids.shape[0],\n",
    "                                self.max_len))\n",
    "        preds_end = np.zeros((input_ids.shape[0],\n",
    "                              self.max_len))\n",
    "        for i in range(n_models):\n",
    "            K.clear_session()\n",
    "            model = self.roberta_model()\n",
    "            model_filename = os.path.join(\n",
    "                self.model_save_path, \n",
    "                '{}-roberta-{}.h5'.format(VER, i)\n",
    "            )\n",
    "            \n",
    "            print('Loading model...')\n",
    "            model.load_weights(model_filename)\n",
    "            \n",
    "            preds = model.predict(\n",
    "                [input_ids, attention_mask, token_type_ids],\n",
    "                verbose=verbose\n",
    "            )\n",
    "            preds_start += preds[0]/n_models\n",
    "            preds_end += preds[1]/n_models\n",
    "        \n",
    "        test_st = self.get_model_selected_text(\n",
    "            data_df=pred_df,\n",
    "            preds_start=preds_start,\n",
    "            preds_end=preds_end\n",
    "        )\n",
    "        return test_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input/tf-roberta/'\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=PATH+'vocab-roberta-base.json', \n",
    "    merges_file=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923b0b35356c4640bb3dbd04bfce5906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = TweetDataset(train, tokenizer, train=True, max_len=MAX_LEN)\n",
    "input_ids, attention_mask, token_type_ids, start_tokens, end_tokens = train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecf8d5787ba4411840554169044ef81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3534.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = TweetDataset(test, tokenizer, train=False, max_len=MAX_LEN)\n",
    "test_input_ids, test_attention_mask, test_token_type_ids = test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_model = TransformerQA(\n",
    "    max_len=MAX_LEN, \n",
    "    model_path=PATH,\n",
    "    model_save_path='../input/tweetextraction-trainedroberta-v0',\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since, it's inference notbook, I won't train\n",
    "\n",
    "# QA_model.fit(train_df=train_data.data, \n",
    "#              input_ids=input_ids, \n",
    "#              attention_mask=attention_mask, \n",
    "#              token_type_ids=token_type_ids, \n",
    "#              start_tokens=start_tokens, \n",
    "#              end_tokens=end_tokens, \n",
    "#              stratify_y=train_data.data.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "3534/3534 [==============================] - 26s 7ms/sample\n",
      "Loading model...\n",
      "3534/3534 [==============================] - 24s 7ms/sample\n",
      "Loading model...\n",
      "3534/3534 [==============================] - 24s 7ms/sample\n",
      "Loading model...\n",
      "3534/3534 [==============================] - 24s 7ms/sample\n",
      "Loading model...\n",
      "3534/3534 [==============================] - 23s 7ms/sample\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained model weights obtained by running training notebook\n",
    "test['selected_text'] = QA_model.predict(pred_df=test, \n",
    "                                         input_ids=test_input_ids, \n",
    "                                         attention_mask=test_attention_mask, \n",
    "                                         token_type_ids=test_token_type_ids, \n",
    "                                         n_models=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['textID','selected_text']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>c4f4b37c8b</td>\n",
       "      <td>very very bad headache that is getting worse b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>very very bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>0c2e7ab834</td>\n",
       "      <td>..my mother just WON the City of Terrell, Texa...</td>\n",
       "      <td>positive</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>10b36df3e0</td>\n",
       "      <td>That didn`t work, unfortunately.</td>\n",
       "      <td>negative</td>\n",
       "      <td>unfortunately.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>e2d8e05859</td>\n",
       "      <td>I`ve run out of earl grey, so having lemon t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>i`ve run out of earl grey,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>b09213d54b</td>\n",
       "      <td>no. my school will start on June1.  two days ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>i still don`t want.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>7e45ea194d</td>\n",
       "      <td>_ aww thats too bad you lost it though</td>\n",
       "      <td>negative</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>abc7f39d90</td>\n",
       "      <td>I`m having lunch already  ur a lil late buddy!</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i`m having lunch already ur a lil late buddy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>a028e284db</td>\n",
       "      <td>What timeeee? My mom says I have to do someth...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what timeeee? my mom says i have to do someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>bb3ef3c925</td>\n",
       "      <td>thanks anyway</td>\n",
       "      <td>positive</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>5f1811bb3d</td>\n",
       "      <td>Good morning twitterland. Happy Monday</td>\n",
       "      <td>positive</td>\n",
       "      <td>good morning twitterland. happy monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>3f8df1fed3</td>\n",
       "      <td>Up late with nothin 2 do.....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>up late with nothin 2 do.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>982b1c05d3</td>\n",
       "      <td>LOVE the album guys and can`t wait for the of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>5b1260de70</td>\n",
       "      <td>the AC tix are actually $20 but the show is s...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sold out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>be634ebeb0</td>\n",
       "      <td>My dead grandpa pays more attention to me than...</td>\n",
       "      <td>negative</td>\n",
       "      <td>dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>3195d34e5b</td>\n",
       "      <td>Good news about the tooth!</td>\n",
       "      <td>positive</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>fcc4f3baa5</td>\n",
       "      <td>ahh ok! Enjoy! I`ll miss it</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ahh ok! enjoy! i`ll miss it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>f02bdad05e</td>\n",
       "      <td>not sure where the real state market is moving...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>not sure where the real state market is movin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>f3c6e98737</td>\n",
       "      <td>_ PrintChick thx for sharen LUV IT</td>\n",
       "      <td>positive</td>\n",
       "      <td>thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>e7a714bd8a</td>\n",
       "      <td>my gawwddd ! 6 headshotss inna row? im on fyaa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>my gawwddd ! 6 headshotss inna row? im on fya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>e09b90939a</td>\n",
       "      <td>Yes, but I`m quite rusty.  I`m hoping to get ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>rusty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>94f0a2521c</td>\n",
       "      <td>_Fur_Laxis It makes me feel physically sick. I...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>935a3c2bf5</td>\n",
       "      <td>Time to put the weapons on the charger for the...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>time to put the weapons on the charger for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>d72a60bee8</td>\n",
       "      <td>are you getting my messages or do you have to...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>are you getting my messages or do you have to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>434e673353</td>\n",
       "      <td>home for the nite, sleeping on the pull out be...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>home for the nite, sleeping on the pull out b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>c7b61da1e2</td>\n",
       "      <td>I feel for you, that sounds like how Kiya was...</td>\n",
       "      <td>positive</td>\n",
       "      <td>enjoy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               text sentiment  \\\n",
       "3084  c4f4b37c8b  very very bad headache that is getting worse b...  negative   \n",
       "3527  0c2e7ab834  ..my mother just WON the City of Terrell, Texa...  positive   \n",
       "1656  10b36df3e0                   That didn`t work, unfortunately.  negative   \n",
       "2840  e2d8e05859    I`ve run out of earl grey, so having lemon t...  negative   \n",
       "1253  b09213d54b   no. my school will start on June1.  two days ...  negative   \n",
       "934   7e45ea194d             _ aww thats too bad you lost it though  negative   \n",
       "1324  abc7f39d90     I`m having lunch already  ur a lil late buddy!   neutral   \n",
       "3196  a028e284db   What timeeee? My mom says I have to do someth...   neutral   \n",
       "3403  bb3ef3c925                                      thanks anyway  positive   \n",
       "881   5f1811bb3d             Good morning twitterland. Happy Monday  positive   \n",
       "1233  3f8df1fed3                      Up late with nothin 2 do.....   neutral   \n",
       "2241  982b1c05d3   LOVE the album guys and can`t wait for the of...  positive   \n",
       "2544  5b1260de70   the AC tix are actually $20 but the show is s...  negative   \n",
       "21    be634ebeb0  My dead grandpa pays more attention to me than...  negative   \n",
       "1906  3195d34e5b                         Good news about the tooth!  positive   \n",
       "1241  fcc4f3baa5                        ahh ok! Enjoy! I`ll miss it   neutral   \n",
       "2005  f02bdad05e  not sure where the real state market is moving...   neutral   \n",
       "3146  f3c6e98737                 _ PrintChick thx for sharen LUV IT  positive   \n",
       "2388  e7a714bd8a  my gawwddd ! 6 headshotss inna row? im on fyaa...  negative   \n",
       "863   e09b90939a   Yes, but I`m quite rusty.  I`m hoping to get ...  negative   \n",
       "2442  94f0a2521c  _Fur_Laxis It makes me feel physically sick. I...  negative   \n",
       "668   935a3c2bf5  Time to put the weapons on the charger for the...   neutral   \n",
       "202   d72a60bee8   are you getting my messages or do you have to...   neutral   \n",
       "801   434e673353  home for the nite, sleeping on the pull out be...   neutral   \n",
       "3232  c7b61da1e2   I feel for you, that sounds like how Kiya was...  positive   \n",
       "\n",
       "                                          selected_text  \n",
       "3084                                      very very bad  \n",
       "3527                                              happy  \n",
       "1656                                     unfortunately.  \n",
       "2840                         i`ve run out of earl grey,  \n",
       "1253                                i still don`t want.  \n",
       "934                                                 bad  \n",
       "1324      i`m having lunch already ur a lil late buddy!  \n",
       "3196   what timeeee? my mom says i have to do someth...  \n",
       "3403                                             thanks  \n",
       "881              good morning twitterland. happy monday  \n",
       "1233                      up late with nothin 2 do.....  \n",
       "2241                                               love  \n",
       "2544                                          sold out.  \n",
       "21                                                 dead  \n",
       "1906                                               good  \n",
       "1241                        ahh ok! enjoy! i`ll miss it  \n",
       "2005   not sure where the real state market is movin...  \n",
       "3146                                                thx  \n",
       "2388   my gawwddd ! 6 headshotss inna row? im on fya...  \n",
       "863                                              rusty.  \n",
       "2442                                              sick.  \n",
       "668    time to put the weapons on the charger for th...  \n",
       "202    are you getting my messages or do you have to...  \n",
       "801    home for the nite, sleeping on the pull out b...  \n",
       "3232                                              enjoy  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "013e23e14f9b4b57aee024addbfe1d7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e182fb642ae4cdfb937ee7ed2536386": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_013e23e14f9b4b57aee024addbfe1d7c",
       "placeholder": "​",
       "style": "IPY_MODEL_46a7d50b9df748cba316e83f543da85f",
       "value": " 3534/3534 [00:01&lt;00:00, 1785.62it/s]"
      }
     },
     "46a7d50b9df748cba316e83f543da85f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4dcdf3fa2aa348ecae231434322a1144": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cba2510d02eb4f2a9f5a2b5b53aa63f7",
       "placeholder": "​",
       "style": "IPY_MODEL_5c4eb11e473147e88c8a88148c0d6fbf",
       "value": " 27480/27480 [00:20&lt;00:00, 1316.22it/s]"
      }
     },
     "5c4eb11e473147e88c8a88148c0d6fbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5e6cfaa8dfef4ca4b9d8c4d1718483e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f107ce7ddd2547989752234915ec7ab9",
       "max": 27480.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dddff6c8feb44c9b84fcff0a1349151d",
       "value": 27480.0
      }
     },
     "6ecf8d5787ba4411840554169044ef81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7e99b3cad09a42ffa19954aa8d6d67ba",
        "IPY_MODEL_2e182fb642ae4cdfb937ee7ed2536386"
       ],
       "layout": "IPY_MODEL_847d954182314e0a8e70c96f0ceb5915"
      }
     },
     "7e99b3cad09a42ffa19954aa8d6d67ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_89033740533b4fb5b53adf9436703f79",
       "max": 3534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e322217adb5c430186db5183f0150e0d",
       "value": 3534.0
      }
     },
     "837746206e734af196379d05feffd84c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "847d954182314e0a8e70c96f0ceb5915": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89033740533b4fb5b53adf9436703f79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "923b0b35356c4640bb3dbd04bfce5906": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5e6cfaa8dfef4ca4b9d8c4d1718483e0",
        "IPY_MODEL_4dcdf3fa2aa348ecae231434322a1144"
       ],
       "layout": "IPY_MODEL_837746206e734af196379d05feffd84c"
      }
     },
     "cba2510d02eb4f2a9f5a2b5b53aa63f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dddff6c8feb44c9b84fcff0a1349151d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e322217adb5c430186db5183f0150e0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f107ce7ddd2547989752234915ec7ab9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
